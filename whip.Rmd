---
title: "era"
author: "Andrew Martin"
date: "May 6, 2015"
output: html_document
---

same methodology as `era.Rmd`, now for WHIP.

```{r data_prep, message=FALSE, error=FALSE, warning=FALSE, include=FALSE}
knitr::knit('stat_avg.Rmd', tangle=TRUE)
source('stat_avg.R')

```


```{r per_out, fig.width = 6, fig.height = 4}

ggplot(
  data = ip_df %>% dplyr::filter(IP >= 1),
  aes(x = wh_per_out)
) +
geom_histogram() +
theme_classic()

```

bin by IP, and then see if the mean and sd converge as IP increases.

```{r mean_conv}

ip_sum <- ip_df %>%
  dplyr::group_by(IP) %>%
  dplyr::summarize(
    n = n(),
    mean_wh_per_out = mean(wh_per_out, na.rm = TRUE),
    sd_wh_per_out = sd(wh_per_out, na.rm = TRUE)
  )

ggplot(
  data = ip_sum %>% dplyr::filter(n >= 25),
  aes(
    x = IP
  )
) +
geom_line(
  aes(y = mean_wh_per_out), 
  color = 'blue'
) +
geom_line(
  aes(y = sd_wh_per_out), 
  color = 'red'
) +
theme_bw() +
labs(y = 'value per out', x = 'IP')

```

blue is mean runs allowed, red is standard deviation.  as expectd, the values definitely stabilize as IP increase.  we'll use those as priors in our model.

let's look at the full distribution:

```{r prior}

prior_df <- ip_df %>%
  dplyr::filter(
    IP_round >= 9 & !is.na(wh_per_out)
  ) %>% as.data.frame()

ggplot(
  data = prior_df,
  aes(
    x = wh_per_out
  )
) +
geom_histogram() +
theme_bw()

```

move the zeros to half of the [smallest positive observation](http://stats.stackexchange.com/a/16867/3320), and then fit as gamma.

```{r kill_zeros}

#minimum non-zero value os 0.0366
prior_df %>% dplyr::filter(
  wh_per_out > 0  
) %>% dplyr::summarize(
  min_wh = min(wh_per_out)
)

prior_df[prior_df$wh_per_out == 0, 'wh_per_out'] <- 0.0366/ 2

library(fitdistrplus)
fit <- fitdist(prior_df$wh_per_out, "gamma")
plot(fit)
```

now we want to simulate draws from our data:
```{r sims}

hist(rgamma(10000, coef(fit)[1], coef(fit)[2]))

```

ok, so that's our prior for true wh per out.  

build generative model:

rather than try to simulate the oddly shaped IP distribution (some weird mixture of gaussians?), we'll just take random draws from the ~6700 observed values.

```{r gen, cache = TRUE}

valid_ip <- ip_df %>% dplyr::filter(IP > 0)

wh_sim <- replicate(10000000, {
  sim_wh_per_out <- rgamma(1, coef(fit)[1], coef(fit)[2])
  sim_true_whip <- sim_wh_per_out * 3
  sim_outs_recorded <- round(sample_n(valid_ip, 1)$IP * 3, 0)
  
  sim_wh <- rpois(sim_outs_recorded, sim_wh_per_out)
  reported_whip <- (sum(sim_wh) / sim_outs_recorded) * 3
  
  c(true_whip = sim_true_whip, IP = sim_outs_recorded / 3, reported_whip = reported_whip)
})  
wh_sim <- t(wh_sim)
head(wh_sim)

p_sim <- density(wh_sim[, 3]) 
plot(p_sim) 

p_true <- density(valid_ip$WHIP)
lines(p_true, col='red', new = FALSE)

```

now let's look at some real data and see how the simulation can help infer the true rates behind the noisy data.

```{r real_data}

wh_sim <- wh_sim %>% as.data.frame()

true_WHIP_est <- function(ip_in, reported_WHIP_in) {

  if(is.na(ip_in)) {
    return(NA)
  }

  wh_sim$rate_diff <- abs(wh_sim$reported_whip - reported_WHIP_in)
  wh_sim$ip_diff <- abs(round(wh_sim$IP, 1) - round(ip_in, 1))
  wh_sim$total_diff <- wh_sim$rate_diff + wh_sim$ip_diff
  wh_sim$rank <- rank(wh_sim$total_diff, ties.method = 'random')
  
  num_exact <- nrow(wh_sim[wh_sim$ip_diff == 0 & wh_sim$rate_diff < 0.1, ])
  if (num_exact > .0005 * nrow(wh_sim)) {
    true_mean <- mean(wh_sim[wh_sim$ip_diff == 0 & wh_sim$rate_diff < 0.1, ]$true_whip)
  } else {
    true_mean <- mean(wh_sim[wh_sim$rank <= .0005 * nrow(wh_sim), ]$true_whip, na.rm=TRUE)
  }

  return(round(true_mean, 2)) 
}

```

# let's use it!

the mean of `true_era` in our simulations is *`r round(mean(era_sim[1, ], na.rm=TRUE),2)`*.  so before we have any data at all, that's our prior about what we think a pitcher's ERA might be.  what is our belief about `true_era` after a number of common outcomes - a pitcher pitches for 1.0 innings, and gives up (respectively) 0, 1, 2, and 3 runs?

```{r use_sim}

true_WHIP_est(1, 0)
true_WHIP_est(1, 3)
true_WHIP_est(1, 6)
true_WHIP_est(1, 9)
```

conditional on those 4 observations, our belief about the true ERA that produced that data would be *`r true_WHIP_est(1, 0)`*, *`r true_WHIP_est(1, 9)`*, *`r true_WHIP_est(1, 18)`*, and *`r  true_WHIP_est(1, 27)`* respectively.  you can see from the distributions for each call that there are a _range_ of possible true ERAs consistent with that data; the mean of that distribution represents our best guess, given the data.

some more tests:

```{r use_sim2}

true_WHIP_est(0.33, 0)
true_WHIP_est(0.33, 3)
true_WHIP_est(0.33, 6)
true_WHIP_est(0.33, 9)
true_WHIP_est(0.33, 12)

true_WHIP_est(12, 1.5)
true_WHIP_est(12, 1.75)
true_WHIP_est(12, 2)
true_WHIP_est(12, 2.25)
true_WHIP_est(12, 2.5)
true_WHIP_est(16, 2.5)
true_WHIP_est(20, 2.5)
```

Now we can apply our `true_WHIP_est` function to all of our historic data:
```{r over_all}

for (i in 1:nrow(ip_df)) {
  print(i)
  ip_df$true_WHIP <- true_WHIP_est(ip_df[i, 'IP'], ip_df[i, 'WHIP'])
}

head(ip_df)

write.csv(ip_df, 'ip_data_whip.csv')
```

